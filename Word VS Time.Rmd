---
title: "WORD VS TIME"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## words under analysis (hack_words=("hack","hacking","hacks","hacker","hacked","hackers"),secrecy_words=("secrecy","secret"),
## "data","users","government","guilt","shame","cybersecurity","databreach","rights","surveillance")




```{r,warning=FALSE, echo=FALSE, cache=TRUE}
## loading required pacakges and Data
memory.limit(100000)
library(ggplot2) # Data visualization
library(ggdendro)
library(readr) # CSV file I/O, e.g. the read_csv function
library(tm) # Package for text mining
library(SnowballC)
library(wordcloud)
library(dplyr)
library(gridExtra)
library(RColorBrewer) # Data Visualization
library(openNLP)
library(koRpus)
library(Rstem)
library(lsa)
### word cloud function
wcloud_Ashley <- function(documents){
     documents = gsub("[^a-zA-Z0-9 ]", "", documents)
    documents= gsub("[[:digit:]]", "",documents)
    documents= gsub("http\\w+", "", documents)
    documents = gsub("\n", "", documents)  
    wordcorpus <- Corpus(VectorSource(documents)) %>% 
    tm_map(content_transformer(tolower)) %>%
    #tm_map(stemDocument,language = "english") %>% 
    tm_map(removePunctuation) %>%
    tm_map(stripWhitespace) %>% 
    tm_map(removeWords,stopwords("english")) %>%
    tm_map(removeWords,
           c("Ashley Madison","ashleymadison","madison","madisons","ashley","http","website",
             "WWW","twitter")) %>%
    DocumentTermMatrix() %>%
    as.matrix() %>%
    as.data.frame()
  return(wordcorpus)
} 

```

## NOTE: WORD FREQUENCIES ARE ADJUSTED TO LOGARITHAMIC SCALE TO ADJUST DIMENSIONS IN THE PLOTS.

### Ashley Madison Incident first 15 days Word Movement
```{r,warning=FALSE, echo=FALSE, cache=TRUE,fig.width=12,fig.height=9}
words_function<-function(df){
date_and_time <- strptime(df$Date..CST., '%m/%d/%Y %H:%M')
df$Date <- as.Date( df$Date, '%m/%d/%Y')
df$Year <- as.numeric(format(date_and_time, '%Y'))
df$Month <- as.numeric(format(date_and_time, '%m'))
df$Day <- as.numeric(format(date_and_time, '%d'))
df$Source=NULL # Source is always twitter and deleted
df$GUID=NULL # GUID is deleted
df$URL=NULL   # user URL is deleted
df$Klout.Score=NULL # Klout.Score is deleted
df$Date..CST.=NULL
df$Author=NULL
df$Name=NULL
df$Country=NULL
df$State.Region=NULL
df$City.Urban.Area=NULL
df$Gender=NULL
df$Posts=NULL
df$Followers=NULL
df$Following=NULL
#names(df)

dates=names(table(df$Date))
for (i in 1:length(dates))
{
  dateval=dates[i]
  tweetset=df[df$Date==dateval,]
  words=wcloud_Ashley(tweetset$Contents)
  word_counts=as.data.frame(cbind(names(words),colSums(words)))
  word_counts$Date=dateval
  names(word_counts)=c("word","Freq","Date")
  if(i==1)
    {
  Group_words=as.data.frame(cbind("",1))
  Group_words$Date=dateval
  names(Group_words)=c("word","Freq","Date")
  }
  Group_words=rbind(word_counts,Group_words)
  #print(i)
  #print(dim(Group_words))
  }

### Obtaining necessary words
attach(Group_words)
word_set=filter(Group_words,word %in% c("secrecy","secret","private","privacy","hack","hacking","hacker","hacked","hacks","hackers","shame","rights",
 "user","data","cybersecurity","datasecurity","datacollection","databreach","surveillance","government","gov","guilt","embarassing"))
word_set$word=factor(word_set$word)
word_set$Freq=factor(word_set$Freq)
word_set$Freq=as.numeric(as.character(word_set$Freq))
word_set$Date=as.Date(word_set$Date)
attach(word_set)
word_set$word=as.character(word_set$word)
word_set[word=="hack",1]="hack_words"
word_set[word=="hacks",1]="hack_words"
word_set[word=="hacker",1]="hack_words"
word_set[word=="hacking",1]="hack_words"
word_set[word=="hacked",1]="hack_words"
word_set[word=="hackers",1]="hack_words"
word_set[word=="secrecy",1]="Secrecy_words"
word_set[word=="secret",1]="Secrecy_words"
word_set[word=="private",1]="Privacy_words"
word_set[word=="privacy",1]="Privacy_words"
word_set[word=="gov",1]="government"
word_set[word=="guilt",1]="gulit_shame"
word_set[word=="shame",1]="gulit_shame"

gby=group_by(word_set,word,Date)
dataframe=summarise(gby,sum(Freq))
dataframe=as.data.frame(dataframe)
dataframe$word=as.factor(dataframe$word)
names(dataframe)=c("word","Date","Freq")

number_ticks <- function(n) {function(limits) pretty(limits, n)}

ggplot(aes(Date, log(Freq),color=word),data=dataframe)+geom_line()+geom_point()+theme(axis.text.x=element_text(angle=45, hjust=1))+ggtitle("Words and time line plot")+scale_color_manual(values=c("red", "blue", "green","yellow","black","darkgreen","maroon","orange","violet","brown","purple"))+xlab("Time frame")+ylab("word frequncy on log scale")+scale_x_date(format(Date, '%m/%d'),breaks=number_ticks(20))
  
}

Ash=read.csv("C:/Users/Jay/Desktop/Prof.Mike/Ashley Madison/Ash2.csv",stringsAsFactors = FALSE)

words_function(Ash)

```


### Edward Snowden Incident first 15 days Word Movement
```{r,warning=FALSE, echo=FALSE, cache=TRUE,fig.width=12,fig.height=9}
Snow1=read.csv("C:/Users/Jay/Desktop/Prof.Mike/Snowden/Snow1.csv",stringsAsFactors = FALSE)
Snow2=read.csv("C:/Users/Jay/Desktop/Prof.Mike/Snowden/Snow2.csv",stringsAsFactors = FALSE)
Snow2=rbind(Snow1,Snow2)
words_function<-function(df){
date_and_time <- strptime(df$Date..CST., '%m/%d/%Y %H:%M')
df$Date <- as.Date( df$Date, '%m/%d/%Y')
df$Year <- as.numeric(format(date_and_time, '%Y'))
df$Month <- as.numeric(format(date_and_time, '%m'))
df$Day <- as.numeric(format(date_and_time, '%d'))
df$Source=NULL # Source is always twitter and deleted
df$GUID=NULL # GUID is deleted
df$URL=NULL   # user URL is deleted
df$Klout.Score=NULL # Klout.Score is deleted
df$Date..CST.=NULL
df$Author=NULL
df$Name=NULL
df$Country=NULL
df$State.Region=NULL
df$City.Urban.Area=NULL
df$Gender=NULL
df$Posts=NULL
df$Followers=NULL
df$Following=NULL
#names(df)

dates=names(table(df$Date))
for (i in 1:length(dates))
{
  dateval=dates[i]
  tweetset=df[df$Date==dateval,]
  words=wcloud_Ashley(tweetset$Contents)
  word_counts=as.data.frame(cbind(names(words),colSums(words)))
  word_counts$Date=dateval
  names(word_counts)=c("word","Freq","Date")
  if(i==1)
    {
  Group_words=as.data.frame(cbind("",1))
  Group_words$Date=dateval
  names(Group_words)=c("word","Freq","Date")
  }
  Group_words=rbind(word_counts,Group_words)
  #print(i)
  #print(dim(Group_words))
  }

### Obtaining necessary words
attach(Group_words)
word_set=filter(Group_words,word %in% c("secrecy","secret","private","privacy","hack","hacking","hacker","hacked","hacks","hackers","shame","rights",
 "user","data","cybersecurity","datasecurity","datacollection","databreach","surveillance","government","gov","guilt","embarassing"))
word_set$word=factor(word_set$word)
word_set$Freq=factor(word_set$Freq)
word_set$Freq=as.numeric(as.character(word_set$Freq))
word_set$Date=as.Date(word_set$Date)
attach(word_set)
word_set$word=as.character(word_set$word)
word_set[word=="hack",1]="hack_words"
word_set[word=="hacks",1]="hack_words"
word_set[word=="hacker",1]="hack_words"
word_set[word=="hacking",1]="hack_words"
word_set[word=="hacked",1]="hack_words"
word_set[word=="hackers",1]="hack_words"
word_set[word=="secrecy",1]="Secrecy_words"
word_set[word=="secret",1]="Secrecy_words"
word_set[word=="private",1]="Privacy_words"
word_set[word=="privacy",1]="Privacy_words"
word_set[word=="gov",1]="government"
word_set[word=="guilt",1]="gulit_shame"
word_set[word=="shame",1]="gulit_shame"

gby=group_by(word_set,word,Date)
dataframe=summarise(gby,sum(Freq))
dataframe=as.data.frame(dataframe)
dataframe$word=as.factor(dataframe$word)
names(dataframe)=c("word","Date","Freq")

number_ticks <- function(n) {function(limits) pretty(limits, n)}

ggplot(aes(Date, log(Freq),color=word),data=dataframe)+geom_line()+geom_point()+theme(axis.text.x=element_text(angle=45, hjust=1))+ggtitle("Words and time line plot")+scale_color_manual(values=c("red", "blue", "green","yellow","black","darkgreen","maroon","orange","violet","brown","purple"))+xlab("Time frame")+ylab("word frequncy on log scale")+scale_x_date(format(Date, '%m/%d'),breaks=number_ticks(20))
  
}

words_function(Snow2)

```


### Celebrity photo hack Incident first 15 days Word Movement
```{r,warning=FALSE, echo=FALSE, cache=TRUE,fig.width=12,fig.height=9}
Celeb2=read.csv("C:/Users/Jay/Desktop/Prof.Mike/Celeb photo hack/Celeb2.csv", stringsAsFactors = FALSE)
words_function<-function(df){
date_and_time <- strptime(df$Date..CST., '%m/%d/%Y %H:%M')
df$Date <- as.Date( df$Date, '%m/%d/%Y')
df$Year <- as.numeric(format(date_and_time, '%Y'))
df$Month <- as.numeric(format(date_and_time, '%m'))
df$Day <- as.numeric(format(date_and_time, '%d'))
df$Source=NULL # Source is always twitter and deleted
df$GUID=NULL # GUID is deleted
df$URL=NULL   # user URL is deleted
df$Klout.Score=NULL # Klout.Score is deleted
df$Date..CST.=NULL
df$Author=NULL
df$Name=NULL
df$Country=NULL
df$State.Region=NULL
df$City.Urban.Area=NULL
df$Gender=NULL
df$Posts=NULL
df$Followers=NULL
df$Following=NULL
#names(df)

dates=names(table(df$Date))
for (i in 1:length(dates))
{
  dateval=dates[i]
  tweetset=df[df$Date==dateval,]
  words=wcloud_Ashley(tweetset$Contents)
  word_counts=as.data.frame(cbind(names(words),colSums(words)))
  word_counts$Date=dateval
  names(word_counts)=c("word","Freq","Date")
  if(i==1)
    {
  Group_words=as.data.frame(cbind("",1))
  Group_words$Date=dateval
  names(Group_words)=c("word","Freq","Date")
  }
  Group_words=rbind(word_counts,Group_words)
  #print(i)
  #print(dim(Group_words))
  }

### Obtaining necessary words
attach(Group_words)
word_set=filter(Group_words,word %in% c("secrecy","secret","private","privacy","hack","hacking","hacker","hacked","hacks","hackers","shame","rights",
 "user","data","cybersecurity","datasecurity","datacollection","databreach","surveillance","government","gov","guilt","embarassing"))
word_set$word=factor(word_set$word)
word_set$Freq=factor(word_set$Freq)
word_set$Freq=as.numeric(as.character(word_set$Freq))
word_set$Date=as.Date(word_set$Date)
attach(word_set)
word_set$word=as.character(word_set$word)
word_set[word=="hack",1]="hack_words"
word_set[word=="hacks",1]="hack_words"
word_set[word=="hacker",1]="hack_words"
word_set[word=="hacking",1]="hack_words"
word_set[word=="hacked",1]="hack_words"
word_set[word=="hackers",1]="hack_words"
word_set[word=="secrecy",1]="Secrecy_words"
word_set[word=="secret",1]="Secrecy_words"
word_set[word=="private",1]="Privacy_words"
word_set[word=="privacy",1]="Privacy_words"
word_set[word=="gov",1]="government"
word_set[word=="guilt",1]="gulit_shame"
word_set[word=="shame",1]="gulit_shame"

gby=group_by(word_set,word,Date)
dataframe=summarise(gby,sum(Freq))
dataframe=as.data.frame(dataframe)
dataframe$word=as.factor(dataframe$word)
names(dataframe)=c("word","Date","Freq")

number_ticks <- function(n) {function(limits) pretty(limits, n)}

ggplot(aes(Date, log(Freq),color=word),data=dataframe)+geom_line()+geom_point()+theme(axis.text.x=element_text(angle=45, hjust=1))+ggtitle("Words and time line plot")+scale_color_manual(values=c("red", "blue", "green","yellow","black","darkgreen","maroon","orange","violet","brown","purple"))+xlab("Time frame")+ylab("word frequncy on log scale")+scale_x_date(format(Date, '%m/%d'),breaks=number_ticks(20))
  
}

words_function(Celeb2)
```


### FBI vs APPLE Incident first 15 days Word Movement
```{r,warning=FALSE, echo=FALSE, cache=TRUE,fig.width=12,fig.height=9}
Apple2=read.csv("C:/Users/Jay/Desktop/Prof.Mike/FBI-APPLE/FBI-APPLE2.csv", stringsAsFactors = FALSE)
words_function<-function(df){
date_and_time <- strptime(df$Date..CST., '%m/%d/%Y %H:%M')
df$Date <- as.Date( df$Date, '%m/%d/%Y')
df$Year <- as.numeric(format(date_and_time, '%Y'))
df$Month <- as.numeric(format(date_and_time, '%m'))
df$Day <- as.numeric(format(date_and_time, '%d'))
df$Source=NULL # Source is always twitter and deleted
df$GUID=NULL # GUID is deleted
df$URL=NULL   # user URL is deleted
df$Klout.Score=NULL # Klout.Score is deleted
df$Date..CST.=NULL
df$Author=NULL
df$Name=NULL
df$Country=NULL
df$State.Region=NULL
df$City.Urban.Area=NULL
df$Gender=NULL
df$Posts=NULL
df$Followers=NULL
df$Following=NULL
#names(df)

dates=names(table(df$Date))
for (i in 1:length(dates))
{
  dateval=dates[i]
  tweetset=df[df$Date==dateval,]
  words=wcloud_Ashley(tweetset$Contents)
  word_counts=as.data.frame(cbind(names(words),colSums(words)))
  word_counts$Date=dateval
  names(word_counts)=c("word","Freq","Date")
  if(i==1)
    {
  Group_words=as.data.frame(cbind("",1))
  Group_words$Date=dateval
  names(Group_words)=c("word","Freq","Date")
  }
  Group_words=rbind(word_counts,Group_words)
  #print(i)
  #print(dim(Group_words))
  }

### Obtaining necessary words
attach(Group_words)
word_set=filter(Group_words,word %in% c("secrecy","secret","private","privacy","hack","hacking","hacker","hacked","hacks","hackers","shame","rights",
 "user","data","cybersecurity","datasecurity","datacollection","databreach","surveillance","government","gov","guilt","embarassing"))
word_set$word=factor(word_set$word)
word_set$Freq=factor(word_set$Freq)
word_set$Freq=as.numeric(as.character(word_set$Freq))
word_set$Date=as.Date(word_set$Date)
attach(word_set)
word_set$word=as.character(word_set$word)
word_set[word=="hack",1]="hack_words"
word_set[word=="hacks",1]="hack_words"
word_set[word=="hacker",1]="hack_words"
word_set[word=="hacking",1]="hack_words"
word_set[word=="hacked",1]="hack_words"
word_set[word=="hackers",1]="hack_words"
word_set[word=="secrecy",1]="Secrecy_words"
word_set[word=="secret",1]="Secrecy_words"
word_set[word=="private",1]="Privacy_words"
word_set[word=="privacy",1]="Privacy_words"
word_set[word=="gov",1]="government"
word_set[word=="guilt",1]="gulit_shame"
word_set[word=="shame",1]="gulit_shame"

gby=group_by(word_set,word,Date)
dataframe=summarise(gby,sum(Freq))
dataframe=as.data.frame(dataframe)
dataframe$word=as.factor(dataframe$word)
names(dataframe)=c("word","Date","Freq")

number_ticks <- function(n) {function(limits) pretty(limits, n)}

ggplot(aes(Date, log(Freq),color=word),data=dataframe)+geom_line()+geom_point()+theme(axis.text.x=element_text(angle=45, hjust=1))+ggtitle("Words and time line plot")+scale_color_manual(values=c("red", "blue", "green","yellow","black","darkgreen","maroon","orange","violet","brown","purple"))+xlab("Time frame")+ylab("word frequncy on log scale")+scale_x_date(format(Date, '%m/%d'),breaks=number_ticks(16))
  
}

words_function(Apple2)
```

```{r}
### extracting needed words
Ash=read.csv("C:/Users/Jay/Desktop/Prof.Mike/Ashley Madison/Ash2.csv",stringsAsFactors = FALSE)
df=Ash
df$ID=1:nrow(df)
df$GUID=NULL
df$URL=NULL
df$Author=NULL
df$Name=NULL
df$Country=NULL
df$State.Region=NULL
df$City.Urban.Area=NULL
df$Source=NULL
df$Klout.Score=NULL
df$Posts=NULL
df$Followers=NULL
df$Following=NULL
names(df)

documents=df$Contents
documents=gsub("[^a-zA-Z0-9 ]", "", documents)
documents=gsub("http\\w+", "", documents) 
#documents=gsub("[[:punct:]]", "",documents )
#gsub("\n", "", documents)
df$Contents=tolower(documents)
df$yes=F

for (i in 1:nrow(df))
    {
      df$yes[i]=grepl("secrecy|secret|private|privacy|hack|hacker|hacked|hacks|hacking|user|breach|collection|cybersecurity|cyber",df$Contents[i])
      #df$yes[i]=grepl(glob2rx("hack*"),df$Contents[i]) || grepl(glob2rx("data*"),df$Contents[i]) || grepl(glob2rx("priva*"),df$Contents[i]) || grepl(glob2rx("secre*"),df$Contents[i]) || grepl(glob2rx("cyber*"),df$Contents[i]) || grepl(glob2rx("embarass*"),df$Contents[i]) || grepl(glob2rx("user*"),df$Contents[i])

}

table(df$yes)
df$yes=as.factor(df$yes)
fildf=df[df$yes==TRUE,]
df=wcloud_Ashley(fildf$Contents)
df$Category=fildf$Category
names(df)


    
    




```

```{r}
Ash=read.csv("C:/Users/Jay/Desktop/Prof.Mike/Ashley Madison/Ash2.csv",stringsAsFactors = FALSE)
df=wcloud_Ashley(Ash$Contents)
df$Category=Ash$Category
names(df)

library(rpart)
tree.mod=rpart(Category~.,data=df,method="class")
summary(tree.mod)
plot(tree.mod)
text(tree.mod,cex = 0.75)

```

